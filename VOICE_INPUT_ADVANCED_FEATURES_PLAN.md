# üöÄ –ü–ª–∞–Ω —É–ª—É—á—à–µ–Ω–∏–π —Å–∏—Å—Ç–µ–º—ã –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞ (Advanced Features)

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 2026-01-19
**–í–µ—Ä—Å–∏—è:** 1.0
**–°—Ç–∞—Ç—É—Å:** Planning Phase

---

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–û–±–∑–æ—Ä](#–æ–±–∑–æ—Ä)
2. [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è](#–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ-–∏–∑–º–µ–Ω–µ–Ω–∏—è)
3. [–§–∏—á–∏ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º](#—Ñ–∏—á–∏-–ø–æ-–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º)
4. [–î–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏](#–¥–µ—Ç–∞–ª—å–Ω—ã–π-–ø–ª–∞–Ω-—Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏)
5. [–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏ —Ä–∏—Å–∫–∏](#–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏-–∏-—Ä–∏—Å–∫–∏)
6. [Timeline –∏ –æ—Ü–µ–Ω–∫–∏](#timeline-–∏-–æ—Ü–µ–Ω–∫–∏)
7. [Testing Strategy](#testing-strategy)

---

## üéØ –û–±–∑–æ—Ä

### –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ

**–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:**
- ‚úÖ –ë–∞–∑–æ–≤–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ (SFSpeechRecognizer)
- ‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ —Å—É–º–º, –∫–∞—Ç–µ–≥–æ—Ä–∏–π, —Å—á–µ—Ç–æ–≤
- ‚úÖ Pre-compiled regex –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- ‚úÖ ML –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (CategoryMLPredictor)
- ‚úÖ Rule-based –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è

**–ü—Ä–æ–±–ª–µ–º—ã:**
- ‚ùå Hardcoded –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ —Å—á–µ—Ç–∞ –≤ –ø–∞—Ä—Å–µ—Ä–µ
- ‚ùå –¢—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏
- ‚ùå –ù–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω–æ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç—è—Ö
- ‚ùå –ü—Ä–æ—Å—Ç–∞—è –∞–Ω–∏–º–∞—Ü–∏—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ –∑–∞–ø–∏—Å–∏
- ‚ùå –ù–∞–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä —Å—á–µ—Ç–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–ø–µ—Ä–≤—ã–π –≤ —Å–ø–∏—Å–∫–µ)
- ‚ùå –ù–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è Speech Recognition

### –¶–µ–ª–µ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ

**–ù–æ–≤—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:**
- ‚úÖ Dynamic Categories: –∂–∏–≤–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å CategoriesViewModel
- ‚úÖ Automatic Silence Detection (VAD)
- ‚úÖ Real-time Entity Highlighting –≤ UI
- ‚úÖ Modern Siri-like Wave Animation
- ‚úÖ Smart Account Defaults –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
- ‚úÖ Dynamic Context Injection –¥–ª—è Speech Recognition

---

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è

### 1. Dependency Injection –¥–ª—è ViewModels

**–¢–µ–∫—É—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**
```swift
// VoiceInputParser.swift
class VoiceInputParser {
    private let accounts: [Account]          // –°—Ç–∞—Ç–∏—á–Ω—ã–π –º–∞—Å—Å–∏–≤
    private let categories: [CustomCategory] // –°—Ç–∞—Ç–∏—á–Ω—ã–π –º–∞—Å—Å–∏–≤
    private let subcategories: [Subcategory] // –°—Ç–∞—Ç–∏—á–Ω—ã–π –º–∞—Å—Å–∏–≤

    init(accounts: [Account], categories: [CustomCategory], subcategories: [Subcategory]) {
        self.accounts = accounts
        self.categories = categories
        self.subcategories = subcategories
    }
}
```

**–ü—Ä–æ–±–ª–µ–º–∞:** –ü–∞—Ä—Å–µ—Ä –ø–æ–ª—É—á–∞–µ—Ç snapshot –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏. –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–æ–±–∞–≤–∏—Ç –Ω–æ–≤—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é, –ø–∞—Ä—Å–µ—Ä –Ω–µ —É–∑–Ω–∞–µ—Ç –æ–± —ç—Ç–æ–º.

**–ù–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**
```swift
// VoiceInputParser.swift
class VoiceInputParser {
    private weak var categoriesViewModel: CategoriesViewModel?
    private weak var accountsViewModel: AccountsViewModel?

    init(categoriesViewModel: CategoriesViewModel, accountsViewModel: AccountsViewModel) {
        self.categoriesViewModel = categoriesViewModel
        self.accountsViewModel = accountsViewModel
    }

    // –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–æ—Å—Ç—É–ø –∫ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    private var liveCategories: [CustomCategory] {
        categoriesViewModel?.customCategories ?? []
    }

    // –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–æ—Å—Ç—É–ø –∫ —Å—á–µ—Ç–∞–º
    private var liveAccounts: [Account] {
        accountsViewModel?.accounts ?? []
    }
}
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ –í—Å–µ–≥–¥–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
- ‚úÖ –ù–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–≤–∞—Ç—å –ø–∞—Ä—Å–µ—Ä
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è

### 2. Voice Activity Detection (VAD) Architecture

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**
```
VoiceInputService
    ‚Üì
SilenceDetector (–Ω–æ–≤—ã–π –∫–ª–∞—Å—Å)
    ‚Üì
AVAudioEngine ‚Üí Audio Buffer Analysis
    ‚Üì
Energy Level Calculation ‚Üí Silence Threshold
    ‚Üì
Callback ‚Üí Auto-stop recording
```

**–ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏:**
- **RMS Energy**: —Å—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≥—Ä–æ–º–∫–æ—Å—Ç–∏
- **Silence Threshold**: –ø–æ—Ä–æ–≥ —Ç–∏—à–∏–Ω—ã (–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π)
- **Silence Duration**: –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–∏—à–∏–Ω—ã –¥–ª—è –∞–≤—Ç–æ-—Å—Ç–æ–ø–∞ (2-3 —Å–µ–∫)

### 3. Real-time Entity Recognition Pipeline

```
Speech Recognition (live)
    ‚Üì
VoiceInputParser.parseLive(partialText)
    ‚Üì
Detected Entities:
    - Amount: NSRange + Confidence
    - Category: NSRange + Confidence
    - Account: NSRange + Confidence
    ‚Üì
UI Update (AttributedString —Å highlights)
```

### 4. Usage Statistics for Smart Defaults

**–ù–æ–≤—ã–π –∫–ª–∞—Å—Å: `AccountUsageTracker`**

```swift
class AccountUsageTracker {
    // –•—Ä–∞–Ω–∏—Ç —á–∞—Å—Ç–æ—Ç—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å—á–µ—Ç–æ–≤
    private var usageCount: [String: Int] = [:]

    // –•—Ä–∞–Ω–∏—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    private var lastUsed: [String: Date] = [:]

    // –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç score –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∞—Å—Ç–æ—Ç—ã –∏ recency
    func getSmartDefaultAccount() -> String?
}
```

**–ê–ª–≥–æ—Ä–∏—Ç–º –≤—ã–±–æ—Ä–∞:**
```
Score = (Usage Count √ó 0.7) + (Recency Factor √ó 0.3)

Recency Factor:
- –ü–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞: 100
- –ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π: 70
- –ü–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π: 40
- –°—Ç–∞—Ä—à–µ 30 –¥–Ω–µ–π: 10
```

---

## üìä –§–∏—á–∏ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º

### Tier 1: Critical (Must Have)

#### 1.1 Dynamic Categories Integration
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ HIGHEST
**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** üü¢ LOW (1-2 —á–∞—Å–∞)
**Impact:** üî¥ HIGH
**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:** –ù–µ—Ç

**–û–ø–∏—Å–∞–Ω–∏–µ:**
–°–≤—è–∑–∞—Ç—å VoiceInputParser —Å live –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ CategoriesViewModel –∏ AccountsViewModel.

**–ü—Ä–∏—á–∏–Ω–∞ –≤—ã—Å–æ–∫–æ–≥–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞:**
- –¢–µ–∫—É—â–∏–π hardcoded —Å–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —É—Å—Ç–∞—Ä–µ–≤–∞–µ—Ç
- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –Ω–µ –º–æ–≥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–≤–æ–∏ –∫–∞—Å—Ç–æ–º–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
- –ö—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –æ–ø—ã—Ç–∞

**–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏:**
```swift
// BEFORE:
let parser = VoiceInputParser(
    accounts: accountsViewModel.accounts,      // snapshot
    categories: categoriesViewModel.categories, // snapshot
    subcategories: categoriesViewModel.subcategories
)

// AFTER:
let parser = VoiceInputParser(
    categoriesViewModel: categoriesViewModel, // reference
    accountsViewModel: accountsViewModel      // reference
)
```

**–§–∞–π–ª—ã –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è:**
1. `VoiceInputParser.swift` - –ø–µ—Ä–µ—Ö–æ–¥ –Ω–∞ weak references
2. `ContentView.swift` - –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä—Å–µ—Ä–∞
3. `VoiceInputView.swift` - –ø–µ—Ä–µ–¥–∞—á–∞ ViewModels –≤–º–µ—Å—Ç–æ –º–∞—Å—Å–∏–≤–æ–≤

---

#### 1.2 Smart Account Defaults
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ HIGH
**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** üü° MEDIUM (2-3 —á–∞—Å–∞)
**Impact:** üü° MEDIUM
**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:** –¢—Ä–µ–±—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π

**–û–ø–∏—Å–∞–Ω–∏–µ:**
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞—Ç—å –Ω–∞–∏–±–æ–ª–µ–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π —Å—á–µ—Ç –≤–º–µ—Å—Ç–æ –ø–µ—Ä–≤–æ–≥–æ –≤ —Å–ø–∏—Å–∫–µ.

**–ê–ª–≥–æ—Ä–∏—Ç–º:**
```swift
func getSmartDefaultAccount(transactions: [Transaction], accounts: [Account]) -> Account? {
    // 1. –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –ø–æ accountId
    let accountUsage = Dictionary(grouping: transactions) { $0.accountId }

    // 2. –°—á–∏—Ç–∞–µ–º score –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—á–µ—Ç–∞
    var scores: [String: Double] = [:]
    for (accountId, txs) in accountUsage {
        let usageScore = Double(txs.count) * 0.7

        // Recency bonus
        let recentTxs = txs.filter {
            Calendar.current.dateComponents([.day], from: $0.date, to: Date()).day ?? 999 < 7
        }
        let recencyScore = Double(recentTxs.count) * 0.3

        scores[accountId] = usageScore + recencyScore
    }

    // 3. –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—á–µ—Ç —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º score
    guard let topAccountId = scores.max(by: { $0.value < $1.value })?.key else {
        return accounts.first // Fallback
    }

    return accounts.first { $0.id == topAccountId }
}
```

**–§–∞–π–ª—ã –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è:**
1. –ù–æ–≤—ã–π —Ñ–∞–π–ª: `Services/AccountUsageTracker.swift`
2. `VoiceInputParser.swift` - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ smart defaults
3. `VoiceInputConfirmationView.swift` - –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Å—á–µ—Ç–∞

---

### Tier 2: Important (Should Have)

#### 2.1 Automatic Silence Detection (VAD)
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü† HIGH
**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** üî¥ HIGH (4-6 —á–∞—Å–æ–≤)
**Impact:** üî¥ HIGH
**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:** –¢—Ä–µ–±—É–µ—Ç —Ä–∞–±–æ—Ç—É —Å AVAudioEngine buffers

**–û–ø–∏—Å–∞–Ω–∏–µ:**
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å –∑–∞–ø–∏—Å—å –ø–æ—Å–ª–µ 2-3 —Å–µ–∫—É–Ω–¥ —Ç–∏—à–∏–Ω—ã.

**–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥:**

**–®–∞–≥ 1: –°–æ–∑–¥–∞—Ç—å SilenceDetector**
```swift
class SilenceDetector {
    private var silenceThreshold: Float = -40.0  // dB
    private var silenceDuration: TimeInterval = 2.5 // —Å–µ–∫—É–Ω–¥—ã
    private var lastSoundTime: Date?
    private var isSilent: Bool = false

    func analyzeSample(_ buffer: AVAudioPCMBuffer) -> Bool {
        // 1. Calculate RMS energy
        let channelData = buffer.floatChannelData?[0]
        let frameLength = Int(buffer.frameLength)

        var sum: Float = 0
        for i in 0..<frameLength {
            let sample = channelData?[i] ?? 0
            sum += sample * sample
        }

        let rms = sqrt(sum / Float(frameLength))
        let db = 20 * log10(rms)

        // 2. Check if silent
        if db < silenceThreshold {
            if lastSoundTime == nil {
                lastSoundTime = Date()
            }

            let silentFor = Date().timeIntervalSince(lastSoundTime!)
            if silentFor >= silenceDuration {
                return true // Silence detected
            }
        } else {
            lastSoundTime = nil
            isSilent = false
        }

        return false
    }

    func reset() {
        lastSoundTime = nil
        isSilent = false
    }
}
```

**–®–∞–≥ 2: –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ VoiceInputService**
```swift
class VoiceInputService {
    private var silenceDetector: SilenceDetector?

    func startRecording() async throws {
        // ... existing code

        silenceDetector = SilenceDetector()

        // Tap audio node –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        let inputNode = audioEngine.inputNode
        let recordingFormat = inputNode.outputFormat(forBus: 0)

        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { [weak self] buffer, _ in
            guard let self = self else { return }

            // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Speech Recognition
            self.recognitionRequest?.append(buffer)

            // –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∏—à–∏–Ω—É
            Task { @MainActor in
                if self.silenceDetector?.analyzeSample(buffer) == true {
                    print("üîá Silence detected - auto stopping")
                    self.stopRecording()
                }
            }
        }
    }
}
```

**–ù–∞—Å—Ç—Ä–æ–π–∫–∏:**
```swift
// VoiceInputConstants.swift
enum VoiceInputConstants {
    // ... existing constants

    // MARK: - Voice Activity Detection

    /// –ü–æ—Ä–æ–≥ —Ç–∏—à–∏–Ω—ã –≤ –¥–µ—Ü–∏–±–µ–ª–∞—Ö (–¥–ë)
    /// –ó–Ω–∞—á–µ–Ω–∏—è –º–µ–Ω—å—à–µ —ç—Ç–æ–≥–æ —Å—á–∏—Ç–∞—é—Ç—Å—è —Ç–∏—à–∏–Ω–æ–π
    static let vadSilenceThresholdDb: Float = -40.0

    /// –ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–∏—à–∏–Ω—ã –¥–ª—è –∞–≤—Ç–æ-—Å—Ç–æ–ø–∞ (—Å–µ–∫—É–Ω–¥—ã)
    static let vadSilenceDuration: TimeInterval = 2.5

    /// –í–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å VAD
    static let vadEnabled: Bool = true
}
```

**UI/UX —É–ª—É—á—à–µ–Ω–∏—è:**
```swift
// VoiceInputView.swift
@State private var isVADEnabled = VoiceInputConstants.vadEnabled

// –î–æ–±–∞–≤–∏—Ç—å toggle
Toggle("–ê–≤—Ç–æ-–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏ —Ç–∏—à–∏–Ω–µ", isOn: $isVADEnabled)
    .padding()
```

**–§–∞–π–ª—ã –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è:**
1. –ù–æ–≤—ã–π —Ñ–∞–π–ª: `Services/Audio/SilenceDetector.swift`
2. `VoiceInputService.swift` - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è VAD
3. `VoiceInputConstants.swift` - –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ VAD –∫–æ–Ω—Å—Ç–∞–Ω—Ç
4. `VoiceInputView.swift` - UI –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ VAD

**–†–∏—Å–∫–∏:**
- ‚ö†Ô∏è False positives (–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏ –ø–∞—É–∑–∞—Ö –≤ —Ä–µ—á–∏)
- ‚ö†Ô∏è Battery drain (–ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ audio buffers)
- ‚ö†Ô∏è Performance –Ω–∞ —Å—Ç–∞—Ä—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö

**Mitigation:**
- –¢—â–∞—Ç–µ–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ thresholds
- Debounce –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç –±—ã—Å—Ç—Ä—ã—Ö –æ—Å—Ç–∞–Ω–æ–≤–æ–∫
- Feature flag –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –Ω–∞ —Å–ª–∞–±—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö

---

#### 2.2 Real-time Entity Highlighting
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü† MEDIUM
**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** üü° MEDIUM (3-4 —á–∞—Å–∞)
**Impact:** üü° MEDIUM
**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:** –¢—Ä–µ–±—É–µ—Ç live parsing

**–û–ø–∏—Å–∞–Ω–∏–µ:**
–ü–æ–¥—Å–≤–µ—á–∏–≤–∞—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ (—Å—É–º–º–∞, –∫–∞—Ç–µ–≥–æ—Ä–∏—è, —Å—á–µ—Ç) –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.

**–í–∏–∑—É–∞–ª—å–Ω—ã–π –¥–∏–∑–∞–π–Ω:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  "500 —Ç–µ–Ω–≥–µ –Ω–∞ —Ç–∞–∫—Å–∏ —Å –∫–∞—Ä—Ç—ã Kaspi" ‚îÇ
‚îÇ   ‚îÄ‚îÄ‚îÄ         ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ         ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ   ‚îÇ
‚îÇ   üü¢          üü°           üü¢        ‚îÇ
‚îÇ  Amount     Category     Account    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üü¢ –ó–µ–ª–µ–Ω—ã–π = High confidence (>0.8)
üü° –ñ–µ–ª—Ç—ã–π = Medium confidence (0.5-0.8)
üî¥ –ö—Ä–∞—Å–Ω—ã–π = Low confidence (<0.5)
```

**–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥:**

**–®–∞–≥ 1: –†–∞—Å—à–∏—Ä–∏—Ç—å –ø–∞—Ä—Å–µ—Ä –¥–ª—è live parsing**
```swift
// VoiceInputParser.swift
struct RecognizedEntity {
    let type: EntityType
    let range: NSRange
    let value: String
    let confidence: Double

    enum EntityType {
        case amount
        case currency
        case category
        case subcategory
        case account
        case date
    }
}

class VoiceInputParser {
    // –ù–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è live parsing
    func parseEntitiesLive(from text: String) -> [RecognizedEntity] {
        var entities: [RecognizedEntity] = []

        // 1. Detect Amount
        if let amountEntity = detectAmount(in: text) {
            entities.append(amountEntity)
        }

        // 2. Detect Category
        if let categoryEntity = detectCategory(in: text) {
            entities.append(categoryEntity)
        }

        // 3. Detect Account
        if let accountEntity = detectAccount(in: text) {
            entities.append(accountEntity)
        }

        return entities
    }

    private func detectAmount(in text: String) -> RecognizedEntity? {
        let nsText = text as NSString

        // –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —á–∏—Å–ª–æ —Å –≤–∞–ª—é—Ç–æ–π
        for regex in amountRegexes {
            if let match = regex.firstMatch(in: text, range: NSRange(location: 0, length: nsText.length)) {
                let matchedText = nsText.substring(with: match.range)
                let confidence = match.range.contains(text.lowercased().range(of: "—Ç–µ–Ω–≥–µ")?.lowerBound) ? 0.9 : 0.7

                return RecognizedEntity(
                    type: .amount,
                    range: match.range,
                    value: matchedText,
                    confidence: confidence
                )
            }
        }

        return nil
    }

    // Similar methods for category, account, etc.
}
```

**–®–∞–≥ 2: –°–æ–∑–¥–∞—Ç—å UI –∫–æ–º–ø–æ–Ω–µ–Ω—Ç —Å highlights**
```swift
// Views/Components/HighlightedText.swift
struct HighlightedText: View {
    let text: String
    let entities: [RecognizedEntity]

    var body: some View {
        Text(attributedString)
            .font(.title3)
            .multilineTextAlignment(.center)
            .padding()
    }

    private var attributedString: AttributedString {
        var attrString = AttributedString(text)

        for entity in entities {
            // Convert NSRange to AttributedString.Index
            if let range = Range(entity.range, in: text) {
                let color = colorForConfidence(entity.confidence)

                attrString[range].backgroundColor = color.opacity(0.2)
                attrString[range].foregroundColor = color
                attrString[range].font = .system(.title3, weight: .bold)
            }
        }

        return attrString
    }

    private func colorForConfidence(_ confidence: Double) -> Color {
        switch confidence {
        case 0.8...1.0: return .green
        case 0.5..<0.8: return .yellow
        default: return .red
        }
    }
}
```

**–®–∞–≥ 3: –û–±–Ω–æ–≤–∏—Ç—å VoiceInputView**
```swift
// VoiceInputView.swift
struct VoiceInputView: View {
    @ObservedObject var voiceService: VoiceInputService
    @State private var recognizedEntities: [RecognizedEntity] = []

    let parser: VoiceInputParser

    var body: some View {
        // ... existing code

        // –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ—Å—Ç–æ–π Text –Ω–∞ HighlightedText
        HighlightedText(
            text: voiceService.transcribedText.isEmpty ? "–ì–æ–≤–æ—Ä–∏—Ç–µ..." : voiceService.transcribedText,
            entities: recognizedEntities
        )
        .onChange(of: voiceService.transcribedText) { newText in
            // Live parsing
            recognizedEntities = parser.parseEntitiesLive(from: newText)
        }
    }
}
```

**–§–∞–π–ª—ã –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è:**
1. `VoiceInputParser.swift` - –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ `parseEntitiesLive()` –∏ `RecognizedEntity`
2. –ù–æ–≤—ã–π —Ñ–∞–π–ª: `Views/Components/HighlightedText.swift`
3. `VoiceInputView.swift` - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è live highlighting
4. `VoiceInputService.swift` - expose partial transcription

---

#### 2.3 Dynamic Context Injection
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü† MEDIUM
**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** üü° MEDIUM (2-3 —á–∞—Å–∞)
**Impact:** üü° MEDIUM
**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:** iOS 17+

**–û–ø–∏—Å–∞–Ω–∏–µ:**
–ò–Ω–∂–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–º–µ–Ω–∞ —Å—á–µ—Ç–æ–≤ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤ Speech Recognition –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏.

**–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥:**

Apple Speech Framework –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç **contextual strings** –Ω–∞—á–∏–Ω–∞—è —Å iOS 17:

```swift
// VoiceInputService.swift
func startRecording() async throws {
    // ... existing code

    recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
    guard let recognitionRequest = recognitionRequest else {
        throw VoiceInputError.recognitionError("Cannot create recognition request")
    }

    // ‚ú® –ù–û–í–û–ï: Dynamic context injection (iOS 17+)
    if #available(iOS 17.0, *) {
        let contextualStrings = buildContextualStrings()
        recognitionRequest.contextualStrings = contextualStrings

        #if DEBUG
        print("üé§ Injected \(contextualStrings.count) contextual strings")
        print("üìã Context: \(contextualStrings.prefix(10))")
        #endif
    }

    // ... rest of code
}

private func buildContextualStrings() -> [String] {
    var context: [String] = []

    // 1. Account names
    if let accountsVM = accountsViewModel {
        let accountNames = accountsVM.accounts.map { $0.name.lowercased() }
        context.append(contentsOf: accountNames)

        // –î–æ–±–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã: "–∫–∞—Ä—Ç–∞ X", "—Å—á–µ—Ç X"
        for name in accountNames {
            context.append("–∫–∞—Ä—Ç–∞ \(name)")
            context.append("—Å—á–µ—Ç \(name)")
            context.append("—Å—á—ë—Ç \(name)")
            context.append("—Å –∫–∞—Ä—Ç—ã \(name)")
            context.append("—Å–æ —Å—á–µ—Ç–∞ \(name)")
        }
    }

    // 2. Category names
    if let categoriesVM = categoriesViewModel {
        let categoryNames = categoriesVM.customCategories.map { $0.name.lowercased() }
        context.append(contentsOf: categoryNames)

        // –î–æ–±–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã: "–Ω–∞ X", "–¥–ª—è X"
        for name in categoryNames {
            context.append("–Ω–∞ \(name)")
            context.append("–¥–ª—è \(name)")
            context.append("–≤ \(name)")
        }
    }

    // 3. Subcategories
    if let categoriesVM = categoriesViewModel {
        let subcategoryNames = categoriesVM.subcategories.map { $0.name.lowercased() }
        context.append(contentsOf: subcategoryNames)
    }

    // 4. Common phrases
    context.append(contentsOf: [
        "—Ç–µ–Ω–≥–µ", "–¥–æ–ª–ª–∞—Ä", "–µ–≤—Ä–æ", "—Ä—É–±–ª—å",
        "–ø–æ–ø–æ–ª–Ω–µ–Ω–∏–µ", "—Ä–∞—Å—Ö–æ–¥", "–¥–æ—Ö–æ–¥",
        "–ø–µ—Ä–µ–≤–æ–¥", "–æ–ø–ª–∞—Ç–∞", "–ø–æ–∫—É–ø–∫–∞"
    ])

    return Array(Set(context)) // Remove duplicates
}
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ Speech Recognition –ª—É—á—à–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–µ—Ç –∏–º–µ–Ω–∞ —Å—á–µ—Ç–æ–≤ ("Kaspi" –≤–º–µ—Å—Ç–æ "–∫–∞—Å–ø–∏")
- ‚úÖ –£–ª—É—á—à–µ–Ω–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
- ‚úÖ –ú–µ–Ω—å—à–µ –æ—à–∏–±–æ–∫ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏

**–§–∞–π–ª—ã –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è:**
1. `VoiceInputService.swift` - –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ `buildContextualStrings()`
2. `VoiceInputParser.swift` - –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ weak references –Ω–∞ ViewModels
3. `VoiceInputConstants.swift` - feature flag –¥–ª—è iOS 17+

---

### Tier 3: Nice to Have

#### 3.1 Siri-like Wave Animation
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü¢ LOW
**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** üü° MEDIUM (3-4 —á–∞—Å–∞)
**Impact:** üü¢ LOW
**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:** –ù–µ—Ç

**–û–ø–∏—Å–∞–Ω–∏–µ:**
–ó–∞–º–µ–Ω–∏—Ç—å –ø—Ä–æ—Å—Ç–æ–π –ø—É–ª—å—Å–∏—Ä—É—é—â–∏–π –∫—Ä–∞—Å–Ω—ã–π –∫—Ä—É–∂–æ–∫ –Ω–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é –≤–æ–ª–Ω–æ–≤—É—é –∞–Ω–∏–º–∞—Ü–∏—é –∫–∞–∫ —É Siri.

**–í–∏–∑—É–∞–ª—å–Ω—ã–π –¥–∏–∑–∞–π–Ω:**
```
Current:              Proposed:
   ‚ö´                  ‚âà‚âà‚âà‚âà‚âà‚âà‚âà‚âà
  ‚óè ‚óè                 ‚âà‚âà‚âà‚âà‚âà‚âà‚âà‚âà‚âà‚âà
 ‚óè   ‚óè       ‚Üí        ‚âà‚âà‚âà‚âà‚âà‚âà‚âà‚âà‚âà‚âà‚âà‚âà
  ‚óè ‚óè                 ‚âà‚âà‚âà‚âà‚âà‚âà‚âà‚âà‚âà‚âà
   ‚ö´                  ‚âà‚âà‚âà‚âà‚âà‚âà‚âà‚âà

Pulsating          Audio-reactive
Red Dot            Wave Animation
```

**–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥:**

**–û–ø—Ü–∏—è 1: Canvas + GeometryEffect (Built-in)**
```swift
// Views/Components/SiriWaveView.swift
struct SiriWaveView: View {
    @State private var phase: Double = 0
    let amplitude: Double
    let frequency: Double

    var body: some View {
        Canvas { context, size in
            let path = createWavePath(size: size, phase: phase)
            context.stroke(path, with: .color(.blue), lineWidth: 3)
        }
        .onAppear {
            withAnimation(.linear(duration: 1.5).repeatForever(autoreverses: false)) {
                phase = 2 * .pi
            }
        }
    }

    private func createWavePath(size: CGSize, phase: Double) -> Path {
        var path = Path()
        let width = size.width
        let height = size.height
        let midY = height / 2

        path.move(to: CGPoint(x: 0, y: midY))

        for x in stride(from: 0, through: width, by: 1) {
            let relativeX = x / width
            let sine = sin((relativeX * frequency * 2 * .pi) + phase)
            let y = midY + (sine * amplitude)

            path.addLine(to: CGPoint(x: x, y: y))
        }

        return path
    }
}
```

**–û–ø—Ü–∏—è 2: Lottie Animation (External)**
```swift
// Using Lottie for professional animation
import Lottie

struct SiriWaveAnimationView: View {
    var body: some View {
        LottieView(animation: .named("siri-wave"))
            .playing(loopMode: .loop)
            .frame(width: 200, height: 100)
    }
}
```

**–û–ø—Ü–∏—è 3: Audio-Reactive Animation (Advanced)**
```swift
// –†–µ–∞–≥–∏—Ä—É–µ—Ç –Ω–∞ –≥—Ä–æ–º–∫–æ—Å—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
struct AudioReactiveWaveView: View {
    @ObservedObject var audioMonitor: AudioLevelMonitor

    var body: some View {
        SiriWaveView(
            amplitude: audioMonitor.level * 50, // Scale by audio level
            frequency: 4
        )
    }
}

class AudioLevelMonitor: ObservableObject {
    @Published var level: Double = 0.0

    func startMonitoring(audioEngine: AVAudioEngine) {
        let inputNode = audioEngine.inputNode
        let recordingFormat = inputNode.outputFormat(forBus: 0)

        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { [weak self] buffer, _ in
            let rms = self?.calculateRMS(buffer: buffer) ?? 0

            DispatchQueue.main.async {
                self?.level = rms
            }
        }
    }

    private func calculateRMS(buffer: AVAudioPCMBuffer) -> Double {
        guard let channelData = buffer.floatChannelData?[0] else { return 0 }
        let frameLength = Int(buffer.frameLength)

        var sum: Float = 0
        for i in 0..<frameLength {
            let sample = channelData[i]
            sum += sample * sample
        }

        return Double(sqrt(sum / Float(frameLength)))
    }
}
```

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –ù–∞—á–∞—Ç—å —Å –û–ø—Ü–∏–∏ 1 (Canvas), —Ç–∞–∫ –∫–∞–∫ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π.

**–§–∞–π–ª—ã –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è:**
1. –ù–æ–≤—ã–π —Ñ–∞–π–ª: `Views/Components/SiriWaveView.swift`
2. `VoiceInputView.swift` - –∑–∞–º–µ–Ω–∞ `RecordingIndicatorView` –Ω–∞ `SiriWaveView`
3. –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: `Services/Audio/AudioLevelMonitor.swift` –¥–ª—è audio-reactive

---

## üì¶ –î–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### Phase 1: Foundation (Week 1)

#### Task 1.1: Dynamic Categories Integration
**–û—Ü–µ–Ω–∫–∞:** 2 —á–∞—Å–∞
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P0

**–®–∞–≥–∏:**
1. ‚úÖ –û–±–Ω–æ–≤–∏—Ç—å `VoiceInputParser.init()` –¥–ª—è –ø—Ä–∏–µ–º–∞ ViewModels
2. ‚úÖ –ò–∑–º–µ–Ω–∏—Ç—å –≤—Å–µ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ `categories` –Ω–∞ `liveCategories`
3. ‚úÖ –û–±–Ω–æ–≤–∏—Ç—å `ContentView.swift` –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ ViewModels
4. ‚úÖ –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –Ω–æ–≤–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤–æ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã

**Acceptance Criteria:**
- [ ] –ü–∞—Ä—Å–µ—Ä –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ ViewModel
- [ ] –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å—Ä–∞–∑—É –¥–æ—Å—Ç—É–ø–Ω–æ –≤ –≥–æ–ª–æ—Å–æ–≤–æ–º –≤–≤–æ–¥–µ
- [ ] –ù–µ—Ç memory leaks (–ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å Instruments)

**Testing:**
```swift
func testDynamicCategoriesIntegration() {
    // 1. –°–æ–∑–¥–∞—Ç—å –ø–∞—Ä—Å–µ—Ä —Å ViewModels
    let parser = VoiceInputParser(
        categoriesViewModel: mockCategoriesVM,
        accountsViewModel: mockAccountsVM
    )

    // 2. –†–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Ç–µ–∫—Å—Ç
    let result1 = parser.parse("500 –Ω–∞ –Ω–æ–≤–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è")
    XCTAssertNil(result1.categoryName) // –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –µ—â–µ –Ω–µ—Ç

    // 3. –î–æ–±–∞–≤–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é
    mockCategoriesVM.addCategory(CustomCategory(name: "–ù–æ–≤–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è", ...))

    // 4. –ü–æ–≤—Ç–æ—Ä–∏—Ç—å –ø–∞—Ä—Å–∏–Ω–≥
    let result2 = parser.parse("500 –Ω–∞ –Ω–æ–≤–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è")
    XCTAssertEqual(result2.categoryName, "–ù–æ–≤–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è") // ‚úÖ –°—Ä–∞–∑—É —Ä–∞–±–æ—Ç–∞–µ—Ç
}
```

---

#### Task 1.2: Smart Account Defaults
**–û—Ü–µ–Ω–∫–∞:** 3 —á–∞—Å–∞
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P0

**–®–∞–≥–∏:**
1. ‚úÖ –°–æ–∑–¥–∞—Ç—å `AccountUsageTracker.swift`
2. ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `getSmartDefaultAccount()` —Å –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º scoring
3. ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ `VoiceInputParser`
4. ‚úÖ –û–±–Ω–æ–≤–∏—Ç—å `VoiceInputConfirmationView` –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤—ã–±–æ—Ä–∞

**Acceptance Criteria:**
- [ ] –ê–ª–≥–æ—Ä–∏—Ç–º –≤—ã–±–∏—Ä–∞–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π —Å—á–µ—Ç
- [ ] –£—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è recency (–Ω–µ–¥–∞–≤–Ω–∏–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –≤–∞–∂–Ω–µ–µ)
- [ ] Fallback –Ω–∞ –ø–µ—Ä–≤—ã–π —Å—á–µ—Ç, –µ—Å–ª–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –Ω–µ—Ç
- [ ] Unit —Ç–µ—Å—Ç—ã –ø–æ–∫—Ä—ã–≤–∞—é—Ç edge cases

**Testing:**
```swift
func testSmartAccountDefaults() {
    // –°—Ü–µ–Ω–∞—Ä–∏–π: 100 —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π —Å Kaspi, 10 —Å Halyk, –ø–æ—Å–ª–µ–¥–Ω—è—è —Å Halyk
    let transactions = [
        // 100x Kaspi (—Å—Ç–∞—Ä—ã–µ)
        Transaction(accountId: "kaspi", date: Date().addingTimeInterval(-30*24*3600)),
        // ...
        // 10x Halyk (–Ω–µ–¥–∞–≤–Ω–∏–µ)
        Transaction(accountId: "halyk", date: Date().addingTimeInterval(-1*24*3600))
    ]

    let tracker = AccountUsageTracker(transactions: transactions)
    let smartDefault = tracker.getSmartDefaultAccount(accounts: mockAccounts)

    // –û–∂–∏–¥–∞–µ–º: Kaspi (frequency wins despite recency of Halyk)
    XCTAssertEqual(smartDefault?.id, "kaspi")
}
```

---

### Phase 2: Voice Activity Detection (Week 2)

#### Task 2.1: Silence Detector
**–û—Ü–µ–Ω–∫–∞:** 4 —á–∞—Å–∞
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P1

**–®–∞–≥–∏:**
1. ‚úÖ –°–æ–∑–¥–∞—Ç—å `SilenceDetector.swift`
2. ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å RMS energy calculation
3. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å threshold logic —Å debounce
4. ‚úÖ Unit —Ç–µ—Å—Ç—ã —Å mock audio buffers

**Acceptance Criteria:**
- [ ] –î–µ—Ç–µ–∫—Ç–æ—Ä –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏—à–∏–Ω—É (RMS < threshold)
- [ ] –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–µ –ø–∞—É–∑—ã –≤ —Ä–µ—á–∏ (< 2 —Å–µ–∫)
- [ ] –°—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ sustained silence (2.5+ —Å–µ–∫)

---

#### Task 2.2: VAD Integration
**–û—Ü–µ–Ω–∫–∞:** 3 —á–∞—Å–∞
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P1

**–®–∞–≥–∏:**
1. ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å `SilenceDetector` –≤ `VoiceInputService`
2. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å callback –¥–ª—è auto-stop
3. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å UI toggle –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è/–≤—ã–∫–ª—é—á–µ–Ω–∏—è VAD
4. ‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ

**Acceptance Criteria:**
- [ ] –ó–∞–ø–∏—Å—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ —Ç–∏—à–∏–Ω—ã
- [ ] –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –æ—Ç–∫–ª—é—á–∏—Ç—å VAD —á–µ—Ä–µ–∑ UI
- [ ] –ù–µ—Ç –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –≤–æ –≤—Ä–µ–º—è —Ä–µ—á–∏

---

### Phase 3: Real-time Feedback (Week 3)

#### Task 3.1: Live Entity Recognition
**–û—Ü–µ–Ω–∫–∞:** 3 —á–∞—Å–∞
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P1

**–®–∞–≥–∏:**
1. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å `parseEntitiesLive()` –≤ `VoiceInputParser`
2. ‚úÖ –°–æ–∑–¥–∞—Ç—å `RecognizedEntity` —Å—Ç—Ä—É–∫—Ç—É—Ä—É
3. ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å detection –¥–ª—è amount, category, account
4. ‚úÖ Unit —Ç–µ—Å—Ç—ã –¥–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ entities

---

#### Task 3.2: Highlighted Text UI
**–û—Ü–µ–Ω–∫–∞:** 3 —á–∞—Å–∞
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P1

**–®–∞–≥–∏:**
1. ‚úÖ –°–æ–∑–¥–∞—Ç—å `HighlightedText.swift` –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
2. ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å AttributedString —Å —Ü–≤–µ—Ç–æ–≤—ã–º–∏ highlights
3. ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ `VoiceInputView`
4. ‚úÖ UI —Ç–µ—Å—Ç—ã –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏

---

### Phase 4: Polish (Week 4)

#### Task 4.1: Dynamic Context Injection
**–û—Ü–µ–Ω–∫–∞:** 2 —á–∞—Å–∞
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P2

**–®–∞–≥–∏:**
1. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å `buildContextualStrings()` –≤ `VoiceInputService`
2. ‚úÖ iOS 17+ feature flag
3. ‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è

---

#### Task 4.2: Siri Wave Animation
**–û—Ü–µ–Ω–∫–∞:** 4 —á–∞—Å–∞
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P3

**–®–∞–≥–∏:**
1. ‚úÖ –°–æ–∑–¥–∞—Ç—å `SiriWaveView.swift` —Å Canvas
2. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å audio-reactive behavior (optional)
3. ‚úÖ –ó–∞–º–µ–Ω–∏—Ç—å `RecordingIndicatorView`

---

## ‚ö†Ô∏è –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏ —Ä–∏—Å–∫–∏

### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

```mermaid
graph TD
    A[Dynamic Categories] --> C[Smart Defaults]
    A --> D[Dynamic Context]
    B[VAD] --> E[Auto-stop UX]
    F[Live Parsing] --> G[Entity Highlighting]
    D --> H[Improved Accuracy]
```

### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏

| –†–∏—Å–∫ | –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å | Impact | Mitigation |
|------|-------------|--------|------------|
| VAD false positives | üü° Medium | üî¥ High | –¢—â–∞—Ç–µ–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ thresholds, feature flag |
| Battery drain (VAD) | üü¢ Low | üü° Medium | –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è buffer size, optional feature |
| iOS 17+ requirement (Context) | üü¢ Low | üü¢ Low | Graceful degradation –¥–ª—è iOS 15/16 |
| Memory leaks (weak refs) | üü¢ Low | üî¥ High | Instruments profiling, unit tests |
| Live parsing performance | üü° Medium | üü° Medium | Debounce, async parsing |

---

## ‚è±Ô∏è Timeline –∏ –æ—Ü–µ–Ω–∫–∏

### Week 1: Foundation
- **Task 1.1** Dynamic Categories: 2h
- **Task 1.2** Smart Defaults: 3h
- Testing & Bug fixes: 2h
- **Total:** 7 hours

### Week 2: VAD
- **Task 2.1** Silence Detector: 4h
- **Task 2.2** Integration: 3h
- Testing on device: 2h
- **Total:** 9 hours

### Week 3: Live Feedback
- **Task 3.1** Entity Recognition: 3h
- **Task 3.2** Highlighted UI: 3h
- Testing & Polish: 2h
- **Total:** 8 hours

### Week 4: Polish
- **Task 4.1** Context Injection: 2h
- **Task 4.2** Wave Animation: 4h
- Final testing: 2h
- **Total:** 8 hours

**Grand Total:** ~32 hours (4 weeks)

---

## üß™ Testing Strategy

### Unit Tests

**VoiceInputParserTests.swift:**
```swift
class VoiceInputParserDynamicTests: XCTestCase {
    var parser: VoiceInputParser!
    var mockCategoriesVM: CategoriesViewModel!
    var mockAccountsVM: AccountsViewModel!

    override func setUp() {
        mockCategoriesVM = CategoriesViewModel(repository: MockRepository())
        mockAccountsVM = AccountsViewModel(repository: MockRepository())
        parser = VoiceInputParser(
            categoriesViewModel: mockCategoriesVM,
            accountsViewModel: mockAccountsVM
        )
    }

    func testDynamicCategoryAddition() {
        // Test: –Ω–æ–≤–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è —Å—Ä–∞–∑—É –¥–æ—Å—Ç—É–ø–Ω–∞
    }

    func testSmartAccountDefaults() {
        // Test: –≤—ã–±–æ—Ä —Å–∞–º–æ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ —Å—á–µ—Ç–∞
    }

    func testLiveEntityRecognition() {
        // Test: —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ entities –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
    }
}
```

**SilenceDetectorTests.swift:**
```swift
class SilenceDetectorTests: XCTestCase {
    func testDetectsSilence() {
        // Test: –¥–µ—Ç–µ–∫—Ü–∏—è —Ç–∏—à–∏–Ω—ã
    }

    func testIgnoresShortPauses() {
        // Test: –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø–∞—É–∑
    }

    func testResetAfterSound() {
        // Test: —Å–±—Ä–æ—Å –ø–æ—Å–ª–µ –∑–≤—É–∫–∞
    }
}
```

### Integration Tests

**VoiceInputIntegrationTests.swift:**
```swift
class VoiceInputIntegrationTests: XCTestCase {
    func testEndToEndVoiceInput() {
        // Test: –ø–æ–ª–Ω—ã–π flow –æ—Ç –∑–∞–ø–∏—Å–∏ –¥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    }

    func testVADAutoStop() {
        // Test: –∞–≤—Ç–æ-–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏ —Ç–∏—à–∏–Ω–µ
    }

    func testLiveHighlighting() {
        // Test: –ø–æ–¥—Å–≤–µ—Ç–∫–∞ entities
    }
}
```

### UI Tests

**VoiceInputUITests.swift:**
```swift
class VoiceInputUITests: XCTestCase {
    func testWaveAnimationAppears() {
        // Test: –∞–Ω–∏–º–∞—Ü–∏—è –≤–æ–ª–Ω –ø–æ—è–≤–ª—è–µ—Ç—Å—è
    }

    func testEntityHighlightingColors() {
        // Test: –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ü–≤–µ—Ç–∞ –¥–ª—è confidence
    }

    func testVADToggle() {
        // Test: toggle –¥–ª—è VAD —Ä–∞–±–æ—Ç–∞–µ—Ç
    }
}
```

### Manual Testing Checklist

**–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:**
- [ ] –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é ‚Üí —Å–∫–∞–∑–∞—Ç—å —Ç–µ–∫—Å—Ç —Å –Ω–µ–π ‚Üí –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
- [ ] –°–æ–∑–¥–∞—Ç—å 50+ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –Ω–∞ –æ–¥–∏–Ω —Å—á–µ—Ç ‚Üí –ø—Ä–æ–≤–µ—Ä–∏—Ç—å smart default
- [ ] –ì–æ–≤–æ—Ä–∏—Ç—å —Å –ø–∞—É–∑–∞–º–∏ ‚Üí VAD –Ω–µ –¥–æ–ª–∂–µ–Ω —Å—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å
- [ ] –ú–æ–ª—á–∞—Ç—å 3 —Å–µ–∫—É–Ω–¥—ã ‚Üí VAD –¥–æ–ª–∂–µ–Ω –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å
- [ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥—Å–≤–µ—Ç–∫—É entities (amount, category, account)
- [ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∞–Ω–∏–º–∞—Ü–∏—é –≤–æ–ª–Ω (–ø–ª–∞–≤–Ω–æ—Å—Ç—å, —Ä–µ–∞–∫—Ü–∏—è –Ω–∞ –∑–≤—É–∫)

**Edge Cases:**
- [ ] –ù–µ—Ç —Å—á–µ—Ç–æ–≤ –≤ —Å–∏—Å—Ç–µ–º–µ ‚Üí –¥–æ–ª–∂–µ–Ω —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ crash
- [ ] –ù–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–π ‚Üí –¥–æ–ª–∂–µ–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å "–î—Ä—É–≥–æ–µ"
- [ ] –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (200+ —Å–∏–º–≤–æ–ª–æ–≤) ‚Üí –Ω–µ—Ç –ª–∞–≥–æ–≤
- [ ] –ë—ã—Å—Ç—Ä–∞—è —Ä–µ—á—å ‚Üí –≤—Å–µ entities —Ä–∞—Å–ø–æ–∑–Ω–∞—é—Ç—Å—è
- [ ] –¢–∏—Ö–∞—è —Ä–µ—á—å ‚Üí VAD –Ω–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø—Ä–µ–∂–¥–µ–≤—Ä–µ–º–µ–Ω–Ω–æ

**Performance:**
- [ ] Memory leak detection (Instruments)
- [ ] Battery drain –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ 5+ –º–∏–Ω—É—Ç
- [ ] UI responsiveness –≤–æ –≤—Ä–µ–º—è live parsing

---

## üìù –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è (Future)

### Phase 5: Advanced Features (Backlog)

1. **Multi-language Support**
   - –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
   - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ English, Kazakh

2. **Voice Commands**
   - "–û—Ç–º–µ–Ω–∞" ‚Üí Cancel recording
   - "–°–æ—Ö—Ä–∞–Ω–∏—Ç—å" ‚Üí Save transaction
   - "–ü–æ–≤—Ç–æ—Ä–∏—Ç—å" ‚Üí Repeat recognition

3. **Offline Mode Improvements**
   - On-device ML –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏
   - Cached speech recognition models

4. **Accessibility**
   - VoiceOver support
   - Haptic feedback –¥–ª—è confirmations

5. **Analytics**
   - Track recognition accuracy
   - Most common errors
   - Usage patterns

---

## üéØ Success Metrics

### Quantitative KPIs

| Metric | Current | Target | Measurement |
|--------|---------|--------|-------------|
| Voice input completion rate | 70% | 90% | Analytics |
| Average correction time | 15s | 5s | Timer |
| Smart default accuracy | N/A | 85% | A/B test |
| Recognition accuracy | 80% | 90% | Manual review |
| VAD false positive rate | N/A | <5% | Error logs |

### Qualitative KPIs

- ‚úÖ User feedback: "Faster and more intuitive"
- ‚úÖ Support tickets: -50% voice input related
- ‚úÖ App Store reviews: mention voice input as strength

---

## üìö Documentation

### –§–∞–π–ª—ã –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

1. **ML_INTEGRATION_GUIDE.md** (update)
   - –î–æ–±–∞–≤–∏—Ç—å —Ä–∞–∑–¥–µ–ª –æ Dynamic Context

2. **VOICE_INPUT_IMPROVEMENTS_SUMMARY.md** (update)
   - –í–µ—Ä—Å–∏—è 2.0 —Å –Ω–æ–≤—ã–º–∏ —Ñ–∏—á–∞–º–∏

3. **VOICE_INPUT_ADVANCED_FEATURES_PLAN.md** (this file)
   - –ü–æ–ª–Ω—ã–π –ø–ª–∞–Ω –∏ —Å—Ç–∞—Ç—É—Å

4. –ù–æ–≤—ã–π: **VOICE_INPUT_VAD_GUIDE.md**
   - –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ Voice Activity Detection
   - –ù–∞—Å—Ç—Ä–æ–π–∫–∞ thresholds
   - Troubleshooting

5. –ù–æ–≤—ã–π: **VOICE_INPUT_API_REFERENCE.md**
   - API documentation –¥–ª—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
   - Usage examples

---

## ‚úÖ Acceptance Criteria (–û–±—â–∏–π)

**–ü–µ—Ä–µ–¥ —Ä–µ–ª–∏–∑–æ–º Phase 1-3:**
- [ ] –í—Å–µ unit —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç (>90% coverage)
- [ ] Integration —Ç–µ—Å—Ç—ã —É—Å–ø–µ—à–Ω—ã
- [ ] Manual testing checklist –∑–∞–≤–µ—Ä—à–µ–Ω
- [ ] No memory leaks (Instruments)
- [ ] Performance benchmarks —Å–æ–±–ª—é–¥–µ–Ω—ã
- [ ] Documentation –æ–±–Ω–æ–≤–ª–µ–Ω–∞
- [ ] Code review –ø—Ä–æ–π–¥–µ–Ω
- [ ] Beta testing –Ω–∞ 10+ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è—Ö

**–ü–µ—Ä–µ–¥ —Ä–µ–ª–∏–∑–æ–º Phase 4:**
- [ ] Wave animation –ø–ª–∞–≤–Ω–∞—è –Ω–∞ –≤—Å–µ—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö
- [ ] Context injection —É–ª—É—á—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ 10%+
- [ ] User feedback –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π
- [ ] App Store submission approved

---

## üìû Support & Contacts

**–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π:** AI Finance Manager Team
**–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞:** 2026-01-19
**Estimated completion:** 2026-02-16 (4 weeks)

---

**–ê–≤—Ç–æ—Ä –ø–ª–∞–Ω–∞:** Claude Sonnet 4.5
**–î–∞—Ç–∞:** 2026-01-19
**–í–µ—Ä—Å–∏—è:** 1.0
